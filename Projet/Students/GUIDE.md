# Projet Deep Learning - Pricing Neural Network

## Objectif du Projet

Construire un r√©seau de neurones en Java pour r√©soudre un **probl√®me de r√©gression** : le pricing d'un produit financier.

- **Analyse comparative** : tester diff√©rentes configurations et choisir la meilleure
- Le r√©seau final s√©rialis√© (meilleure performance)

---

## Fonctionnalit√©s Impl√©ment√©es

### Hands-on 1 : Forward Propagation
- Propagation avant dans le r√©seau
- Validation sur la fonction AND
- Refactoring pour r√©duire les instanciations

### Hands-on 2 : Backpropagation
- Chargement/Sauvegarde de r√©seaux (JSON)
- Backpropagation et descente de gradient
- Tests sur AND, Sin, Cos

### Hands-on 3 : Mini-batch & Momentum
- **Mini-batch** : Entra√Ænement par paquets (taille configurable)
- **Momentum** : Acc√©l√©ration du gradient (impl√©ment√© dans `StandardLayer`)
- Tests comparatifs : `and_expe.json` vs `and_expe_momentum.json`

### Hands-on 4 : R√©gularisation
- **L2 Regularization** : P√©nalisation des poids pour √©viter l'overfitting
- Configurable par couche dans les fichiers JSON

### Pricing Neural Network (6h)
- Donn√©es disponibles dans `pricing-data/`
- **√Ä faire** : Entra√Æner et comparer diff√©rents r√©seaux

---

## Plan d'Exp√©rimentation (Tests √† R√©aliser)

Le rapport doit contenir une **analyse comparative** de plusieurs configurations de r√©seaux. Voici les tests √† effectuer :

### 1. **Architecture du R√©seau**
Tester diff√©rentes configurations :
- Nombre de couches cach√©es : 1, 2, 3 couches
- Taille des couches : 10, 20, 50 neurones
- Fonctions d'activation : `Tanh`, `Relu`, `LeakyRelu`, `Sigmoid`

**Fichiers √† cr√©er :**
```
pricing-data/experiments/
‚îú‚îÄ‚îÄ network_1layer_20neurons.json
‚îú‚îÄ‚îÄ network_2layers_10_10.json
‚îú‚îÄ‚îÄ network_3layers_20_10_5.json
‚îî‚îÄ‚îÄ ...
```

### 2. **Hyperparam√®tres d'Apprentissage**
Comparer l'impact de :
- **Learning Rate** : 0.001, 0.01, 0.1
- **Batch Size** : 16, 32, 64, 128
- **Momentum** : 0 (sans), 0.9, 0.95
- **Epochs** : 1000, 5000, 10000

**Fichiers √† cr√©er :**
```
pricing-data/experiments/
‚îú‚îÄ‚îÄ expe_lr_0.001.json
‚îú‚îÄ‚îÄ expe_lr_0.01.json
‚îú‚îÄ‚îÄ expe_momentum_0.9.json
‚îî‚îÄ‚îÄ ...
```

### 3. **R√©gularisation**
Tester avec/sans r√©gularisation :
- Sans r√©gularisation L2
- Avec L2 (Œª = 0.0001, 0.001, 0.01)

### 4. **Normalisation des Donn√©es** 
- Input Standardization : $\frac{x-\mu}{\sigma}$

**Tests √† faire :**
- R√©seau **sans** normalisation
- R√©seau **avec** normalisation (devrait converger beaucoup plus vite)

### 5. **Initialisation des Poids**
Comparer les initialiseurs :
- `Xavier` (recommand√© pour Tanh/Sigmoid)
- `He` (recommand√© pour ReLU)
- `Gaussian` (al√©atoire standard)

---

## M√©triques √† Analyser

Pour **chaque exp√©rience**, collecter et comparer :

### 1. **Courbes d'Erreur**
- Tracer `Training Error` vs `Validation Error` (fichiers `.csv` g√©n√©r√©s)
- **V√©rifier** :
  - Convergence : L'erreur diminue-t-elle ?
  - Overfitting : L'erreur de validation remonte-t-elle ?
  - Vitesse : Combien d'√©poques pour atteindre 1% d'erreur ?

**Commande pour tracer :**
```bash
python Examples/TrainingConsole/plot.py
```

### 2. **Erreur Finale**
- Erreur sur le jeu de **validation**
- Erreur sur le jeu de **test** (pricing-data/test.csv)

### 3. **Inspection des Poids**
Ouvrir les fichiers `*_learned.json` et v√©rifier :
- Les poids sont-ils dans un range raisonnable (-10, +10) ?
- Ou explosent-ils (1e6) ‚Üí instabilit√©
- Sont-ils trop petits (~0) ‚Üí le r√©seau n'a rien appris

### 4. **Temps d'Entra√Ænement**
- Noter le temps d'ex√©cution (visible dans les logs Maven)

---

## Structure des Donn√©es de Test

```
pricing-data/
‚îú‚îÄ‚îÄ train.csv          # Donn√©es d'entra√Ænement (70%)
‚îú‚îÄ‚îÄ valid.csv          # Donn√©es de validation (15%)
‚îú‚îÄ‚îÄ test.csv           # Donn√©es de test final (15%)
‚îî‚îÄ‚îÄ experiments/       # Vos fichiers de configuration
    ‚îú‚îÄ‚îÄ network_*.json
    ‚îî‚îÄ‚îÄ expe_*.json
```

---

## Lancer une Exp√©rience

### 1. Cr√©er un fichier de configuration d'exp√©rience

**Exemple : `pricing-data/experiments/expe_baseline.json`**
```json
{
    "network description": "pricing-data/experiments/network_baseline.json",
    "training data": "pricing-data/train.csv",
    "validation data": "pricing-data/valid.csv",
    "epochs": 5000,
    "trained network": "pricing-data/results/baseline_learned.json",
    "cost function": "Quadratic",
    "initialize": true,
    "learning log file": "pricing-data/results/baseline_error.csv",
    "validation steps": 100,
    "final validation": "pricing-data/results/baseline_validation.csv",
    "activation file": "pricing-data/results/baseline_activation.csv",
    "gnuplot": false
}
```

### 2. Cr√©er le fichier r√©seau correspondant

**Exemple : `pricing-data/experiments/network_baseline.json`**
```json
{
  "InputSize": 5,
  "BatchSize": 32,
  "Initializer": "Xavier",
  "Layers": [
    {
      "Size": 20,
      "ActivatorType": "Tanh",
      "Type": "Standard",
      "GradientAdjustmentParameters": {
        "Type": "Momentum",
        "LearningRate": 0.01,
        "Momentum": 0.9
      },
      "L2Regularization": 0.0001
    },
    {
      "Size": 10,
      "ActivatorType": "Tanh",
      "Type": "Standard",
      "GradientAdjustmentParameters": {
        "Type": "Momentum",
        "LearningRate": 0.01,
        "Momentum": 0.9
      }
    },
    {
      "Size": 1,
      "ActivatorType": "Identity",
      "Type": "Standard",
      "GradientAdjustmentParameters": {
        "Type": "FixedLearningRate",
        "LearningRate": 0.01
      }
    }
  ]
}
```

### 3. Lancer l'entra√Ænement

```bash
mvn exec:java -Dexec.mainClass="fr.ensimag.deep.trainingConsole.Main" \
  -Dexec.args="-x pricing-data/experiments/expe_baseline.json"
```

### 4. Analyser les r√©sultats

- Ouvrir `pricing-data/results/baseline_error.csv`
- Tracer la courbe avec Python/gnuplot
- Comparer avec les autres exp√©riences

---

## R√©sultats Exp√©rimentaux (14 exp√©riences - 7 inputs)

### Tableau Comparatif des Exp√©riences (AVEC normalisation)

| Rang | Exp√©rience | Architecture | Activation | LR | Momentum | L2 | **MSE Valid** | RMSE | Temps |
|------|------------|--------------|------------|----|----------|----|---------------|------|-------|
| 1 | **baseline_norm** | 7-20-10-1 | Tanh | 0.01 | 0.9 | 0.0001 | **0.49** | 0.70 | ~20s |
| 2 | **no_regularization_norm** | 7-20-10-1 | Tanh | 0.01 | 0.9 | **0** | **0.49** | 0.70 | ~20s |
| 3 | relu_norm | 7-20-10-1 | ReLU | 0.01 | 0.9 | 0.0001 | **0.51** | 0.72 | ~29s |
| 4 | no_momentum_norm | 7-20-10-1 | Tanh | 0.01 | **0** | 0.0001 | **0.51** | 0.72 | ~20s |
| 5 | deep_norm | 7-50-20-10-1 | Tanh | 0.01 | 0.9 | 0.001 | **0.68** | 0.83 | ~1m48s |
| 6 | simple_norm | 7-7-1 | Tanh | 0.01 | 0.9 | 0.0001 | **0.69** | 0.83 | ~10s |
| 7 | lr_high_norm | 7-20-10-1 | Tanh | **0.1** | 0.9 | 0.0001 | 5.42 | 2.33 | ~20s |

### Tableau Comparatif (SANS normalisation)

| Rang | Exp√©rience | MSE Valid | RMSE |
|------|------------|-----------|------|
| 1 | relu | 18.43 | 4.29 |
| 2 | deep | 18.43 | 4.29 |
| 3 | no_momentum | 18.44 | 4.29 |
| 4 | baseline | 18.46 | 4.30 |
| 5 | no_regularization | 18.49 | 4.30 |
| 6 | lr_high | 18.73 | 4.33 |
| 7 | simple | 19.32 | 4.40 |

**Toutes les exp√©riences sans normalisation ont des MSE entre 18-19 (tr√®s coh√©rent).**

### Analyse des R√©sultats

#### üèÜ Meilleur R√©seau : **baseline_norm** ou **no_regularization_norm**

Deux r√©seaux ex-aequo avec MSE = 0.49 :

**Configuration recommand√©e : no_regularization_norm**
- **Architecture** : 7-20-10-1 (2 couches cach√©es)
- **Activation** : Tanh
- **Hyperparam√®tres** : LR=0.01, Momentum=0.9, L2=0 (pas de r√©gularisation)
- **Performance Validation** : MSE=0.49, RMSE=0.70
- **Temps d'entra√Ænement** : ~20 secondes
- **Fichier** : `pricing-data/results/no_regularization_norm_learned.json`

**Justification :**
- Performance identique √† baseline_norm
- Plus simple (pas de r√©gularisation L2)
- Principe du rasoir d'Ockham : pr√©f√©rer la solution la plus simple

#### üìä Observations Cl√©s (D√©couvertes via HiPlot)

**1. Impact MASSIF de la Normalisation ‚≠ê‚≠ê‚≠ê**
- **Sans normalisation** : MSE moyen = 18.5
- **Avec normalisation** : MSE moyen = 0.6
- **Am√©lioration** : **-97%** d'erreur !
- **Conclusion** : La normalisation est **LE facteur d√©cisif**. Sans elle, impossible d'obtenir de bons r√©sultats.

**2. Architecture : Impact Marginal (avec normalisation)**
- **Simple (7-7-1)** : MSE = 0.69
- **Standard (7-20-10-1)** : MSE = 0.49
- **Deep (7-50-20-10-1)** : MSE = 0.68
- **Conclusion** : Avec normalisation, m√™me un r√©seau minimal (1 couche cach√©e) performe tr√®s bien. Pas besoin de complexit√© excessive.

**3. Momentum : Devient Optionnel (avec normalisation)**
- **Avec momentum (0.9)** : MSE = 0.49
- **Sans momentum (0)** : MSE = 0.51 (seulement +4%)
- **Conclusion** : Contrairement aux attentes, le momentum n'est plus critique avec normalisation. La normalisation stabilise l'optimisation.

**4. R√©gularisation L2 : Inutile (avec normalisation)**
- **Sans L2 (0)** : MSE = 0.49
- **Avec L2 (0.0001)** : MSE = 0.49
- **Avec L2 (0.001)** : MSE = 0.68
- **Conclusion** : La r√©gularisation n'apporte rien, voire d√©grade l√©g√®rement. La normalisation pr√©vient d√©j√† l'overfitting.

**5. Activation : Tanh ‚âà ReLU (avec normalisation)**
- **Tanh** : MSE = 0.49
- **ReLU** : MSE = 0.51
- **Conclusion** : Les deux fonctions sont √©quivalentes avec normalisation.

**6. Learning Rate : Toujours Critique**
- **LR = 0.01** : MSE = 0.49-0.69 ‚úÖ
- **LR = 0.1** : MSE = 5.42 ‚ùå (10√ó pire)
- **Conclusion** : M√™me avec normalisation, un LR trop √©lev√© cause divergence.

### Graphiques et Visualisations

**HiPlot (interactif)** :
- `pricing-data/results/hiplot_visualization.html` : Exploration interactive de tous les hyperparam√®tres
- Permet de filtrer, comparer et identifier visuellement les patterns

**Courbes d'apprentissage** :
- `pricing-data/results/*_convergence.png` : √âvolution de l'erreur pour chaque exp√©rience
- `pricing-data/results/normalization_impact.png` : Comparaison avec/sans normalisation

---

## Visualisation Interactive avec HiPlot

**HiPlot** (Facebook Research) permet d'explorer visuellement les 14 exp√©riences avec de multiples hyperparam√®tres.

### Utilisation

```bash
pip install hiplot
bash pricing-data/run_hiplot.sh
```

Ouvre `pricing-data/results/hiplot_visualization.html` dans le navigateur.

### Interface

**Parallel Coordinates Plot:**
- Chaque ligne = une exp√©rience
- Chaque axe = un hyperparam√®tre ou m√©trique
- Cliquer-glisser sur un axe pour filtrer

**Axes importants:** `validation_mse`, `normalized`, `learning_rate`, `momentum`, `architecture`

**D√©couvertes cl√©s via HiPlot:**
- Impact massif de la normalisation (-97% d'erreur)
- Momentum optionnel avec normalisation
- R√©gularisation L2 inutile
- Architecture simple suffit

Voir `HIPLOT_README.md` pour plus de d√©tails.

---

## Choix du Meilleur R√©seau

**Crit√®res de s√©lection :**
1. **Erreur de validation la plus faible**
2. Simplicit√© (rasoir d'Ockham)
3. Temps d'entra√Ænement raisonnable
4. Pas d'overfitting

**R√©seau final recommand√© :**
- **Fichier** : `pricing-data/results/no_regularization_norm_learned.json`
- **Architecture** : 7-20-10-1 (avec normalisation)
- **Hyperparam√®tres** : LR=0.01, Momentum=0.9, L2=0
- **MSE validation** : 0.49
- **RMSE** : 0.70
- **Temps** : 20 secondes

**Alternative (identique) :**
- `pricing-data/results/baseline_norm_learned.json` (MSE=0.49)

---

## Contenu du Rapport

Le rapport doit contenir :

### 1. Introduction
- Objectif du projet
- Description du probl√®me de pricing
- Expliquer la demarche (implementation pour and, sin, cos,...)

### 2. Impl√©mentation
- Fonctionnalit√©s d√©velopp√©es (Forward, Backprop, Mini-batch, Momentum, L2)
- Normalisation 
- Architecture du code

### 3. Exp√©rimentation
- **Tableau comparatif** (comme ci-dessus)
- **Courbes d'erreur** pour chaque exp√©rience
- **Analyse** : 
  - Impact du learning rate
  - Impact du momentum
  - Impact de la normalisation
  - Impact de l'architecture (profondeur, largeur)

### 4. R√©sultats
- Meilleur r√©seau s√©lectionn√©
- Justification du choix
- Erreur finale sur le jeu de test

### 5. Conclusion
- Difficult√©s rencontr√©es
- Am√©liorations possibles (Batch Normalization, Dropout, Adam optimizer...)

---

---


### Rapport
- [ ] R√©diger l'introduction
- [ ] Documenter l'impl√©mentation
- [ ] Inclure le tableau comparatif
- [ ] Ajouter les graphiques
- [ ] Justifier le choix du meilleur r√©seau
- [ ] Conclusion

---

## Commandes Utiles

### Lancer toutes les exp√©riences
```bash
bash pricing-data/RUN_ALL.sh
```

### Analyser tous les r√©sultats
```bash
# Comparaison avec/sans normalisation
python3 pricing-data/compare_normalization.py

# Analyse compl√®te
python3 pricing-data/complete_analysis.py

# Tracer les courbes de convergence
python3 pricing-data/plot_convergence.py

# Inspecter les poids (d√©tecter explosion/neurones morts)
python3 pricing-data/inspect_weights.py
```

### Visualisation interactive HiPlot
```bash
# Lancer HiPlot (installe automatiquement si n√©cessaire)
bash pricing-data/run_hiplot.sh

# Ou directement
python3 pricing-data/hiplot_analysis.py
```

### √âvaluer le meilleur r√©seau (validation + test)
```bash
python3 pricing-data/evaluate_normalized.py
```

### Lancer une exp√©rience sp√©cifique
```bash
mvn exec:java -Dexec.mainClass="fr.ensimag.deep.trainingConsole.Main" \
  -Dexec.args="-x pricing-data/experiments/expe_baseline.json"
```

**R√©sultats:**
- Validation: MSE=67.45, RMSE=8.21
- Test: MSE=66.22, RMSE=8.14
- Diff√©rence: 1.83% -> Excellente g√©n√©ralisation