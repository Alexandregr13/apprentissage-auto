# Projet Deep Learning - Pricing Neural Network

## üìã Objectif du Projet

Construire un r√©seau de neurones en Java pour r√©soudre un **probl√®me de r√©gression** : le pricing d'un produit financier.

- **Analyse comparative** : tester diff√©rentes configurations et choisir la meilleure
- Le r√©seau final s√©rialis√© (meilleure performance)

---

## Fonctionnalit√©s Impl√©ment√©es

### Hands-on 1 : Forward Propagation
- Propagation avant dans le r√©seau
- Validation sur la fonction AND
- Refactoring pour r√©duire les instanciations

### Hands-on 2 : Backpropagation
- Chargement/Sauvegarde de r√©seaux (JSON)
- Backpropagation et descente de gradient
- Tests sur AND, Sin, Cos

### Hands-on 3 : Mini-batch & Momentum
- **Mini-batch** : Entra√Ænement par paquets (taille configurable)
- **Momentum** : Acc√©l√©ration du gradient (impl√©ment√© dans `StandardLayer`)
- Tests comparatifs : `and_expe.json` vs `and_expe_momentum.json`

### Hands-on 4 : R√©gularisation
- **L2 Regularization** : P√©nalisation des poids pour √©viter l'overfitting
- Configurable par couche dans les fichiers JSON

### Pricing Neural Network (6h)
- Donn√©es disponibles dans `pricing-data/`
- **√Ä faire** : Entra√Æner et comparer diff√©rents r√©seaux

---

## Plan d'Exp√©rimentation (Tests √† R√©aliser)

Le rapport doit contenir une **analyse comparative** de plusieurs configurations de r√©seaux. Voici les tests √† effectuer :

### 1. **Architecture du R√©seau**
Tester diff√©rentes configurations :
- Nombre de couches cach√©es : 1, 2, 3 couches
- Taille des couches : 10, 20, 50 neurones
- Fonctions d'activation : `Tanh`, `Relu`, `LeakyRelu`, `Sigmoid`

**Fichiers √† cr√©er :**
```
pricing-data/experiments/
‚îú‚îÄ‚îÄ network_1layer_20neurons.json
‚îú‚îÄ‚îÄ network_2layers_10_10.json
‚îú‚îÄ‚îÄ network_3layers_20_10_5.json
‚îî‚îÄ‚îÄ ...
```

### 2. **Hyperparam√®tres d'Apprentissage**
Comparer l'impact de :
- **Learning Rate** : 0.001, 0.01, 0.1
- **Batch Size** : 16, 32, 64, 128
- **Momentum** : 0 (sans), 0.9, 0.95
- **Epochs** : 1000, 5000, 10000

**Fichiers √† cr√©er :**
```
pricing-data/experiments/
‚îú‚îÄ‚îÄ expe_lr_0.001.json
‚îú‚îÄ‚îÄ expe_lr_0.01.json
‚îú‚îÄ‚îÄ expe_momentum_0.9.json
‚îî‚îÄ‚îÄ ...
```

### 3. **R√©gularisation**
Tester avec/sans r√©gularisation :
- Sans r√©gularisation L2
- Avec L2 (Œª = 0.0001, 0.001, 0.01)

### 4. **Normalisation des Donn√©es** ‚ö†Ô∏è √Ä IMPL√âMENTER
- Input Standardization : $\frac{x-\mu}{\sigma}$

**Tests √† faire :**
- R√©seau **sans** normalisation
- R√©seau **avec** normalisation (devrait converger beaucoup plus vite)

### 5. **Initialisation des Poids**
Comparer les initialiseurs :
- `Xavier` (recommand√© pour Tanh/Sigmoid)
- `He` (recommand√© pour ReLU)
- `Gaussian` (al√©atoire standard)

---

## M√©triques √† Analyser

Pour **chaque exp√©rience**, collecter et comparer :

### 1. **Courbes d'Erreur**
- Tracer `Training Error` vs `Validation Error` (fichiers `.csv` g√©n√©r√©s)
- **V√©rifier** :
  - Convergence : L'erreur diminue-t-elle ?
  - Overfitting : L'erreur de validation remonte-t-elle ?
  - Vitesse : Combien d'√©poques pour atteindre 1% d'erreur ?

**Commande pour tracer :**
```bash
python Examples/TrainingConsole/plot.py
```

### 2. **Erreur Finale**
- Erreur sur le jeu de **validation**
- Erreur sur le jeu de **test** (pricing-data/test.csv)

### 3. **Inspection des Poids**
Ouvrir les fichiers `*_learned.json` et v√©rifier :
- Les poids sont-ils dans un range raisonnable (-10, +10) ?
- Ou explosent-ils (1e6) ‚Üí instabilit√©
- Sont-ils trop petits (~0) ‚Üí le r√©seau n'a rien appris

### 4. **Temps d'Entra√Ænement**
- Noter le temps d'ex√©cution (visible dans les logs Maven)

---

## Structure des Donn√©es de Test

```
pricing-data/
‚îú‚îÄ‚îÄ train.csv          # Donn√©es d'entra√Ænement (70%)
‚îú‚îÄ‚îÄ valid.csv          # Donn√©es de validation (15%)
‚îú‚îÄ‚îÄ test.csv           # Donn√©es de test final (15%)
‚îî‚îÄ‚îÄ experiments/       # Vos fichiers de configuration
    ‚îú‚îÄ‚îÄ network_*.json
    ‚îî‚îÄ‚îÄ expe_*.json
```

---

## Lancer une Exp√©rience

### 1. Cr√©er un fichier de configuration d'exp√©rience

**Exemple : `pricing-data/experiments/expe_baseline.json`**
```json
{
    "network description": "pricing-data/experiments/network_baseline.json",
    "training data": "pricing-data/train.csv",
    "validation data": "pricing-data/valid.csv",
    "epochs": 5000,
    "trained network": "pricing-data/results/baseline_learned.json",
    "cost function": "Quadratic",
    "initialize": true,
    "learning log file": "pricing-data/results/baseline_error.csv",
    "validation steps": 100,
    "final validation": "pricing-data/results/baseline_validation.csv",
    "activation file": "pricing-data/results/baseline_activation.csv",
    "gnuplot": false
}
```

### 2. Cr√©er le fichier r√©seau correspondant

**Exemple : `pricing-data/experiments/network_baseline.json`**
```json
{
  "InputSize": 5,
  "BatchSize": 32,
  "Initializer": "Xavier",
  "Layers": [
    {
      "Size": 20,
      "ActivatorType": "Tanh",
      "Type": "Standard",
      "GradientAdjustmentParameters": {
        "Type": "Momentum",
        "LearningRate": 0.01,
        "Momentum": 0.9
      },
      "L2Regularization": 0.0001
    },
    {
      "Size": 10,
      "ActivatorType": "Tanh",
      "Type": "Standard",
      "GradientAdjustmentParameters": {
        "Type": "Momentum",
        "LearningRate": 0.01,
        "Momentum": 0.9
      }
    },
    {
      "Size": 1,
      "ActivatorType": "Identity",
      "Type": "Standard",
      "GradientAdjustmentParameters": {
        "Type": "FixedLearningRate",
        "LearningRate": 0.01
      }
    }
  ]
}
```

### 3. Lancer l'entra√Ænement

```bash
mvn exec:java -Dexec.mainClass="fr.ensimag.deep.trainingConsole.Main" \
  -Dexec.args="-x pricing-data/experiments/expe_baseline.json"
```

### 4. Analyser les r√©sultats

- Ouvrir `pricing-data/results/baseline_error.csv`
- Tracer la courbe avec Python/gnuplot
- Comparer avec les autres exp√©riences

---

## üìà Tableau Comparatif (√Ä Remplir)

| Exp√©rience | Architecture | LR | Momentum | L2 | Normalisation | Erreur Train | Erreur Valid | Temps |
|------------|--------------|----|-----------|----|---------------|--------------|--------------|-------|
| baseline   | 20-10-1 Tanh | 0.01 | 0.9 | 0.0001 | Non | ? | ? | ? |
| lr_high    | 20-10-1 Tanh | 0.1 | 0.9 | 0.0001 | Non | ? | ? | ? |
| no_momentum| 20-10-1 Tanh | 0.01 | 0 | 0.0001 | Non | ? | ? | ? |
| normalized | 20-10-1 Tanh | 0.01 | 0.9 | 0.0001 | **Oui** | ? | ? | ? |
| deep_net   | 50-20-10-1 Tanh | 0.01 | 0.9 | 0.001 | Oui | ? | ? | ? |

---

## üéØ Choix du Meilleur R√©seau

**Crit√®res de s√©lection :**
1. **Erreur de validation la plus faible**
2. Pas d'overfitting (erreur train environ egale √† l'erreur valid)
3. Temps d'entra√Ænement raisonnable
4. Stabilit√© (poids coh√©rents)

**R√©seau final √† soumettre :**
- Le fichier `*_learned.json` avec les meilleures performances
- Accompagn√© d'une justification dans le rapport

---

## Contenu du Rapport

Le rapport doit contenir :

### 1. Introduction
- Objectif du projet
- Description du probl√®me de pricing

### 2. Impl√©mentation
- Fonctionnalit√©s d√©velopp√©es (Forward, Backprop, Mini-batch, Momentum, L2)
- Normalisation 
- Architecture du code

### 3. Exp√©rimentation
- **Tableau comparatif** (comme ci-dessus)
- **Courbes d'erreur** pour chaque exp√©rience
- **Analyse** : 
  - Impact du learning rate
  - Impact du momentum
  - Impact de la normalisation
  - Impact de l'architecture (profondeur, largeur)

### 4. R√©sultats
- Meilleur r√©seau s√©lectionn√©
- Justification du choix
- Erreur finale sur le jeu de test

### 5. Conclusion
- Difficult√©s rencontr√©es
- Am√©liorations possibles (Batch Normalization, Dropout, Adam optimizer...)

---

## üîß TODO List

### Impl√©mentation
- [ ] **Input Standardization** 
  - Calculer Œº et œÉ sur les donn√©es d'entra√Ænement
  - Normaliser train, valid et test avec ces valeurs
  
### Exp√©rimentation
- [ ] Cr√©er le dossier `pricing-data/experiments/`
- [ ] Cr√©er le dossier `pricing-data/results/`
- [ ] G√©n√©rer les fichiers de configuration pour chaque test
- [ ] Lancer toutes les exp√©riences
- [ ] Collecter les r√©sultats dans un tableau Excel/CSV

### Analyse
- [ ] Tracer toutes les courbes d'erreur
- [ ] Comparer les performances
- [ ] Inspecter les poids du meilleur r√©seau
- [ ] Tester le r√©seau final sur `test.csv`

### Rapport
- [ ] R√©diger l'introduction
- [ ] Documenter l'impl√©mentation
- [ ] Inclure le tableau comparatif
- [ ] Ajouter les graphiques
- [ ] Justifier le choix du meilleur r√©seau
- [ ] Conclusion

